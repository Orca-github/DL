{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x21a30ed3040>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n",
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels =1,out_channels = 6,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels =6,out_channels = 12,kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4,out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120,out_features=60)\n",
    "        self.out = nn.Linear(in_features=60,out_features=10)\n",
    "\n",
    "    def forward(self,t):\n",
    "        #t = t #第一层输入\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size =2,stride=2)\n",
    "\n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t,kernel_size = 2,stride =2)\n",
    "\n",
    "        t = t.reshape(-1,12*4*4)\n",
    "        t = F.relu(self.fc1(t))\n",
    "\n",
    "        t = F.relu(self.fc2(t))\n",
    "\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds,labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 嵌套迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct: 46413 loss: 35664.55728709698\n",
      "epoch 1 total_correct: 51241 loss: 23663.543684780598\n",
      "epoch 2 total_correct: 52090 loss: 21554.387152194977\n",
      "epoch 3 total_correct: 52542 loss: 20280.790719389915\n",
      "epoch 4 total_correct: 52607 loss: 20125.938968360424\n",
      "epoch 0 total_correct: 42355 loss: 46275.923442840576\n",
      "epoch 1 total_correct: 48414 loss: 30926.167038083076\n",
      "epoch 2 total_correct: 50421 loss: 26373.330394923687\n",
      "epoch 3 total_correct: 51440 loss: 23576.00471228361\n",
      "epoch 4 total_correct: 52081 loss: 21781.836453080177\n",
      "epoch 0 total_correct: 31997 loss: 83450.43635964394\n",
      "epoch 1 total_correct: 42256 loss: 48080.176001787186\n",
      "epoch 2 total_correct: 43812 loss: 43287.657472491264\n",
      "epoch 3 total_correct: 44680 loss: 40765.75691998005\n",
      "epoch 4 total_correct: 45349 loss: 39031.01156055927\n",
      "epoch 0 total_correct: 6139 loss: 137815.8599615097\n",
      "epoch 1 total_correct: 23518 loss: 134062.07616329193\n",
      "epoch 2 total_correct: 28548 loss: 116921.44904136658\n",
      "epoch 3 total_correct: 31769 loss: 89918.07047128677\n",
      "epoch 4 total_correct: 36845 loss: 71798.78267645836\n",
      "epoch 0 total_correct: 35228 loss: 65237.766683101654\n",
      "epoch 1 total_correct: 46879 loss: 34743.55039000511\n",
      "epoch 2 total_correct: 48905 loss: 29913.479208946228\n",
      "epoch 3 total_correct: 50341 loss: 26494.19179558754\n",
      "epoch 4 total_correct: 51173 loss: 24027.259469032288\n",
      "epoch 0 total_correct: 28129 loss: 91999.376475811\n",
      "epoch 1 total_correct: 43014 loss: 44995.68033218384\n",
      "epoch 2 total_correct: 45023 loss: 39061.077535152435\n",
      "epoch 3 total_correct: 46029 loss: 35754.40555810928\n",
      "epoch 4 total_correct: 46875 loss: 33572.01638817787\n",
      "epoch 0 total_correct: 6938 loss: 137437.593460083\n",
      "epoch 1 total_correct: 23268 loss: 130065.44804573059\n",
      "epoch 2 total_correct: 29510 loss: 100907.62853622437\n",
      "epoch 3 total_correct: 37343 loss: 69933.39240550995\n",
      "epoch 4 total_correct: 39591 loss: 58381.97076320648\n",
      "epoch 0 total_correct: 6000 loss: 138225.3258228302\n",
      "epoch 1 total_correct: 6000 loss: 138126.39021873474\n",
      "epoch 2 total_correct: 5998 loss: 137997.62725830078\n",
      "epoch 3 total_correct: 6005 loss: 137830.65557479858\n",
      "epoch 4 total_correct: 6088 loss: 137615.2205467224\n",
      "epoch 0 total_correct: 16247 loss: 123168.28966140747\n",
      "epoch 1 total_correct: 30556 loss: 77995.82600593567\n",
      "epoch 2 total_correct: 37656 loss: 57297.82938957214\n",
      "epoch 3 total_correct: 40382 loss: 50741.1915063858\n",
      "epoch 4 total_correct: 42309 loss: 45015.12348651886\n",
      "epoch 0 total_correct: 7006 loss: 137850.91400146484\n",
      "epoch 1 total_correct: 14424 loss: 135711.91787719727\n",
      "epoch 2 total_correct: 23177 loss: 129615.99826812744\n",
      "epoch 3 total_correct: 28842 loss: 115282.35077857971\n",
      "epoch 4 total_correct: 34397 loss: 90763.60821723938\n",
      "epoch 0 total_correct: 6000 loss: 138113.06953430176\n",
      "epoch 1 total_correct: 6000 loss: 137941.69902801514\n",
      "epoch 2 total_correct: 6000 loss: 137758.69131088257\n",
      "epoch 3 total_correct: 6000 loss: 137550.311088562\n",
      "epoch 4 total_correct: 6008 loss: 137300.46272277832\n",
      "epoch 0 total_correct: 6000 loss: 138330.90782165527\n",
      "epoch 1 total_correct: 6000 loss: 138320.8155632019\n",
      "epoch 2 total_correct: 6000 loss: 138310.8353614807\n",
      "epoch 3 total_correct: 6000 loss: 138300.96006393433\n",
      "epoch 4 total_correct: 6000 loss: 138291.19205474854\n"
     ]
    }
   ],
   "source": [
    "batch_size_list = [100, 1000, 10000]\n",
    "lr_list = [.01, .001, .0001, .00001]\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    for lr in lr_list:\n",
    "        network = Network()\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_set, batch_size=batch_size\n",
    "        )\n",
    "        optimizer = optim.Adam(\n",
    "            network.parameters(), lr=lr\n",
    "        )\n",
    "\n",
    "        images, labels = next(iter(train_loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        comment=f' batch_size={batch_size} lr={lr}'\n",
    "        tb = SummaryWriter(comment=comment)\n",
    "        tb.add_image('images', grid)\n",
    "        tb.add_graph(network, images)\n",
    "\n",
    "        for epoch in range(5):\n",
    "            total_loss = 0\n",
    "            total_correct = 0\n",
    "            for batch in train_loader:\n",
    "                images, labels = batch # Get Batch\n",
    "                preds = network(images) # Pass Batch\n",
    "                loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "                optimizer.zero_grad() # Zero Gradients\n",
    "                loss.backward() # Calculate Gradients\n",
    "                optimizer.step() # Update Weights\n",
    "\n",
    "                total_loss += loss.item() * batch_size\n",
    "                total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "            tb.add_scalar(\n",
    "                'Loss', total_loss, epoch\n",
    "            )\n",
    "            tb.add_scalar(\n",
    "                'Number Correct', total_correct, epoch\n",
    "            )\n",
    "            tb.add_scalar(\n",
    "                'Accuracy', total_correct / len(train_set), epoch\n",
    "            )\n",
    "\n",
    "            for name, param in network.named_parameters():\n",
    "                tb.add_histogram(name, param, epoch)\n",
    "                tb.add_histogram(f'{name}.grad', param.grad, epoch)\n",
    "\n",
    "            print(\n",
    "                \"epoch\", epoch\n",
    "                ,\"total_correct:\", total_correct\n",
    "                ,\"loss:\", total_loss\n",
    "            )  \n",
    "        tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5])\n",
      "conv1.bias torch.Size([6])\n",
      "conv2.weight torch.Size([12, 6, 5, 5])\n",
      "conv2.bias torch.Size([12])\n",
      "fc1.weight torch.Size([120, 192])\n",
      "fc1.bias torch.Size([120])\n",
      "fc2.weight torch.Size([60, 120])\n",
      "fc2.bias torch.Size([60])\n",
      "out.weight torch.Size([10, 60])\n",
      "out.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "for name, weight in network.named_parameters():\n",
    "    print(name,weight.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight.grad None\n",
      "conv1.bias.grad None\n",
      "conv2.weight.grad None\n",
      "conv2.bias.grad None\n",
      "fc1.weight.grad None\n",
      "fc1.bias.grad None\n",
      "fc2.weight.grad None\n",
      "fc2.bias.grad None\n",
      "out.weight.grad None\n",
      "out.bias.grad None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, weight in network.named_parameters():\n",
    "    print(f'{name}.grad',weight.grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不同参数遍历写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将参数放入一个字典中\n",
    "parameters = dict(\n",
    "    lr = [.01,.001]\n",
    "    ,batch_size = [10,100,1000]\n",
    "    ,suffle = [True,False]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.01, 0.001], [10, 100, 1000], [True, False]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_values = [v for v in parameters.values()]\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 10 True\n",
      "0.01 10 False\n",
      "0.01 100 True\n",
      "0.01 100 False\n",
      "0.01 1000 True\n",
      "0.01 1000 False\n",
      "0.001 10 True\n",
      "0.001 10 False\n",
      "0.001 100 True\n",
      "0.001 100 False\n",
      "0.001 1000 True\n",
      "0.001 1000 False\n"
     ]
    }
   ],
   "source": [
    "for lr,batch_size,suffle in product(*param_values):\n",
    "    print(lr,batch_size,suffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr,batch_size,shuffle in product(*param_values):\n",
    "    comment = f'batch_size={batch_size} lr = {lr} shuffle ={shuffle}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values): \n",
    "    comment = f' batch_size={batch_size} lr={lr} shuffle={shuffle}'\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set\n",
    "        ,batch_size=batch_size\n",
    "        ,shuffle=shuffle \n",
    "    )\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "        network.parameters(), lr=lr\n",
    "    )\n",
    "\n",
    "    network = Network()\n",
    "\n",
    "\n",
    "    images,labels = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    tb.add_image('images',grid)\n",
    "    tb.add_graph(network,images)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for batch in train_loader:\n",
    "            images,labels = batch\n",
    "            \n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds,labels)\n",
    "            #------------要将梯度归零 因为pytorch会累加梯度\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()#计算梯度\n",
    "            optimizer.step()#更新梯度\n",
    "\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_correct += get_num_correct(preds,labels)\n",
    "    #scalar 数字\n",
    "        tb.add_scalar('loss',total_loss,epoch)\n",
    "        tb.add_scalar('Number Correcnt',total_correct,epoch)\n",
    "        tb.add_scalar('Accuracy',total_correct/len(train_set),epoch)\n",
    "        \n",
    "        for name,param in network.named_parameters():\n",
    "            tb.add_histogram(name,param,epoch)\n",
    "            tb.add_histogram(f'{name}.grad,param,gard,epoch param')\n",
    "        \n",
    "        print(\"epoch:\",epoch,\"total_correct\",total_correct,\" loss:\",total_loss)\n",
    "\n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae51ee3d492f24e83e77a52eb34bf16365894f8747390aa8e17995579dedf394"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
